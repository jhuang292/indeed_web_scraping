{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rithika suggested I merge all of the find_alls into one large function, so the code below was created with her assistance. \n",
    "\n",
    "def parse(url):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "    for each in soup.find_all(class_= \"result\" ):\n",
    "        try: \n",
    "            title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "        except:\n",
    "            title = 'None'\n",
    "        try:\n",
    "            location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "        except:\n",
    "            location = 'None'\n",
    "        try: \n",
    "            company = each.find(class_='company').text.replace('\\n', '')\n",
    "        except:\n",
    "            company = 'None'\n",
    "#         try:\n",
    "#             salary = each.find('span', {'class':'no-wrap'}).text\n",
    "#         except:\n",
    "#             salary = 'None'\n",
    "#         synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "        df = df.append({'Title':title, 'Location':location, 'Company':company}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist (Big Data)</td>\n",
       "      <td>None</td>\n",
       "      <td>Columbia Consulting Group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Risk Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>MoneyLion, Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Digitalogy Consulting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY 10014 (West Village area)</td>\n",
       "      <td>RapidIT Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MODA Data Scientist</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>New York City DEPT OF INFO TECH &amp; TELE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Insights</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Getty Images</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY 10005 (Financial District area)</td>\n",
       "      <td>Attune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Remedy Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist, Customer Operations</td>\n",
       "      <td>New York, NY 10014 (West Village area)</td>\n",
       "      <td>Squarespace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist (NY)</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Debtsy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>RISIRISA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data and Statistics Intern</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>United Nations Development Programme (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Applied Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>None</td>\n",
       "      <td>Delaware North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Disney Streaming Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  \\\n",
       "0             Data Scientist (Big Data)   \n",
       "1                   Risk Data Scientist   \n",
       "2                        Data Scientist   \n",
       "3                        Data Scientist   \n",
       "4                   MODA Data Scientist   \n",
       "5             Data Scientist - Insights   \n",
       "6                        Data Scientist   \n",
       "7                 Junior Data Scientist   \n",
       "8   Data Scientist, Customer Operations   \n",
       "9                   Data Scientist (NY)   \n",
       "10                       Data Scientist   \n",
       "11           Data and Statistics Intern   \n",
       "12               Applied Data Scientist   \n",
       "13                    Data Scientist II   \n",
       "14                       Data Scientist   \n",
       "\n",
       "                                        Location  \\\n",
       "0                                           None   \n",
       "1                                           None   \n",
       "2                                   New York, NY   \n",
       "3         New York, NY 10014 (West Village area)   \n",
       "4                                  Manhattan, NY   \n",
       "5                                   New York, NY   \n",
       "6   New York, NY 10005 (Financial District area)   \n",
       "7                                   New York, NY   \n",
       "8         New York, NY 10014 (West Village area)   \n",
       "9                                   New York, NY   \n",
       "10                                  New York, NY   \n",
       "11                                  New York, NY   \n",
       "12                                          None   \n",
       "13                                          None   \n",
       "14                                          None   \n",
       "\n",
       "                                              Company Salary Synopsis  \n",
       "0                           Columbia Consulting Group    NaN      NaN  \n",
       "1                                      MoneyLion, Inc    NaN      NaN  \n",
       "2                               Digitalogy Consulting    NaN      NaN  \n",
       "3                                         RapidIT Inc    NaN      NaN  \n",
       "4           New York City DEPT OF INFO TECH & TELE...    NaN      NaN  \n",
       "5                                        Getty Images    NaN      NaN  \n",
       "6                                              Attune    NaN      NaN  \n",
       "7                                     Remedy Partners    NaN      NaN  \n",
       "8                                         Squarespace    NaN      NaN  \n",
       "9                                              Debtsy    NaN      NaN  \n",
       "10                                           RISIRISA    NaN      NaN  \n",
       "11          United Nations Development Programme (...    NaN      NaN  \n",
       "12                                        CyberCoders    NaN      NaN  \n",
       "13                                     Delaware North    NaN      NaN  \n",
       "14                          Disney Streaming Services    NaN      NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York, NY 10104 (Midtown area)',\n",
       " 'New York, NY 10011 (Chelsea area)',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY 10014 (West Village area)',\n",
       " 'New York, NY 10036',\n",
       " 'New York, NY 10036',\n",
       " 'Central Islip, NY',\n",
       " 'New York, NY 10005 (Financial District area)']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'location'})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)\n",
    "extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nielsen',\n",
       " 'MoneyLion, Inc',\n",
       " 'Transport Learning',\n",
       " 'Chembio Diagnostic Systems, Inc.',\n",
       " 'VISITING NURSE SERVICE OF NEW YORK',\n",
       " 'PS&S',\n",
       " 'AETNA',\n",
       " 'IBM',\n",
       " 'Spotify',\n",
       " 'Bonobos',\n",
       " 'FINDYR',\n",
       " 'Facebook',\n",
       " 'Spotify',\n",
       " 'Netlan Technology',\n",
       " 'Digitalogy Consulting',\n",
       " 'Spotify',\n",
       " 'Strategic Financial Solutions',\n",
       " 'Disney Streaming Services']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary_from_result(soup): \n",
    "    salaries = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            salaries.append(div.find('nobr').text)\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name=\"div\", attrs={\"class\":\"sjcl\"})\n",
    "                div_three = div_two.find(\"div\")\n",
    "                salaries.append(div_three.text.strip())\n",
    "            except:\n",
    "                salaries.append(\"Nothing_found\")\n",
    "    return(salaries)\n",
    "extract_salary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York, NY 10104 (Midtown area)',\n",
       " 'New York, NY 10011 (Chelsea area)',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY 10014 (West Village area)',\n",
       " 'New York, NY 10036',\n",
       " 'New York, NY 10036',\n",
       " 'Central Islip, NY',\n",
       " 'New York, NY 10005 (Financial District area)']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'location'})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)\n",
    "extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bloomberg\\n\\n\\n736 reviews',\n",
       " 'Disney Streaming Services\\n\\n\\n7 reviews',\n",
       " 'Epic Pharma LLC',\n",
       " 'Chembio Diagnostic Systems, Inc.\\n\\n\\n10 reviews',\n",
       " 'Digitas\\n\\n\\n167 reviews',\n",
       " 'Spotify\\n\\n\\n48 reviews',\n",
       " 'Butterfly Network',\n",
       " 'Thasos Group',\n",
       " 'American Express\\n\\n\\n6,847 reviews',\n",
       " 'Transport Learning',\n",
       " 'Celonis',\n",
       " 'Quantilus\\n\\n\\n2 reviews',\n",
       " 'Hopper',\n",
       " 'zioqu',\n",
       " '81qd',\n",
       " 'Noom Inc.\\n\\n\\n9 reviews']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary_from_result(soup): \n",
    "    salaries = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            salaries.append(div.find('nobr').text)\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name=\"div\", attrs={\"class\":\"sjcl\"})\n",
    "                div_three = div_two.find(\"div\")\n",
    "                salaries.append(div_three.text.strip())\n",
    "            except:\n",
    "                salaries.append(\"Nothing_found\")\n",
    "    return(salaries)\n",
    "extract_salary_from_result(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "    summaries = []\n",
    "    spans = soup.findAll('span', attrs={'class':'summary'})\n",
    "    for span in spans:\n",
    "        summaries.append(span.text.strip())\n",
    "    return(summaries)\n",
    "extract_summary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
